{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "KNN_for_semeval_val.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi\n",
        "!wget http://nlp.stanford.edu/data/glove.6B.zip\n",
        "!unzip -q glove.6B.zip"
      ],
      "metadata": {
        "id": "90qK_fohDCot",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a8c804a0-4e07-4749-9b90-10b4b17718e1"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: nvidia-smi: command not found\n",
            "--2022-02-13 09:23:18--  http://nlp.stanford.edu/data/glove.6B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
            "--2022-02-13 09:23:18--  https://nlp.stanford.edu/data/glove.6B.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
            "--2022-02-13 09:23:19--  http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: ‘glove.6B.zip’\n",
            "\n",
            "glove.6B.zip        100%[===================>] 822.24M  5.04MB/s    in 2m 40s  \n",
            "\n",
            "2022-02-13 09:25:59 (5.14 MB/s) - ‘glove.6B.zip’ saved [862182613/862182613]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gHdtkkNH_lDW",
        "outputId": "4b1e64c7-9d52-426a-cf2a-daeaa05f76d5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10000,) (10000,)\n",
            "5000\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "import re\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score\n",
        "train_df = pd.read_csv('mami_training.csv', sep='\\t', lineterminator='\\r')\n",
        "test_df = pd.read_csv('Test.csv', sep='\\t', lineterminator='\\n')\n",
        "test_labels = pd.read_csv('test_labels.txt',header=None, sep='\\t', lineterminator='\\n')\n",
        "X = train_df['Text Transcription'].copy()\n",
        "for i in range(len(X)):\n",
        "  X[i] = X[i].lower()\n",
        "X_test_model = test_df['Text Transcription'].to_numpy()\n",
        "for i in range(len(X_test_model)):\n",
        "  X_test_model[i] = X_test_model[i].lower()\n",
        "Y = train_df['misogynous']\n",
        "X_train_model = X[:].to_numpy()\n",
        "Y_train_model = Y[:].to_numpy()\n",
        "print(X_train_model.shape, Y_train_model.shape)\n",
        "print(Y_train_model.sum())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings_index = {}\n",
        "\n",
        "f = open('glove.6B.200d.txt')\n",
        "for line in f:\n",
        "    values = line.split()\n",
        "    word = value = values[0]\n",
        "    coefs = np.asarray(values[1:], dtype='float32')\n",
        "    embeddings_index[word] = coefs\n",
        "f.close()\n",
        "\n",
        "print('Found %s word vectors.' %len(embeddings_index))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J77pLTH0OHUa",
        "outputId": "1a4ce505-4cb9-4ffe-ffbe-755526a31d44"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 400000 word vectors.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.python.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.python.keras.preprocessing.sequence  import pad_sequences\n",
        "\n",
        "tokenizer_obj = Tokenizer()\n",
        "total_memes =  train_df['Text Transcription']\n",
        "tokenizer_obj.fit_on_texts(total_memes)\n",
        "\n",
        "max_length = 50 #max([len(s.split()) for s in total_memes])\n",
        "vocab_size  = len(tokenizer_obj.word_index) + 1\n",
        "X_train_tokens = tokenizer_obj.texts_to_sequences(X_train_model)\n",
        "X_test_tokens = tokenizer_obj.texts_to_sequences(X_test_model)\n",
        "X_train_pad = pad_sequences(X_train_tokens, maxlen=max_length)\n",
        "X_test_pad = pad_sequences(X_test_tokens, maxlen=max_length)\n",
        "print(vocab_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qIdPEBUBOZ2s",
        "outputId": "1f88a1d1-68a0-4782-bfc0-8715236fafbb"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20693\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "EMBEDDING_DIM = 200\n",
        "word_index = tokenizer_obj.word_index\n",
        "embedding_matrix = np.zeros((vocab_size, EMBEDDING_DIM))\n",
        "for word, i in word_index.items():\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None:\n",
        "      embedding_matrix[i] = embedding_vector\n",
        "\n",
        "def average_glove(df):\n",
        "  real_X = np.zeros((len(df) , EMBEDDING_DIM))\n",
        "  for i in range(len(df)):\n",
        "    num = 0\n",
        "    for word in df[i]:\n",
        "      num += 1\n",
        "      real_X[i] += embedding_matrix[int(word)]\n",
        "    if num!=0:\n",
        "      real_X[i] = real_X[i]/num\n",
        "  return real_X\n",
        "\n",
        "X_train_pad_2_vec = average_glove(X_train_pad)\n",
        "X_test_pad_2_vec = average_glove(X_test_pad)\n",
        "print(X_test_pad_2_vec.shape,X_train_pad_2_vec.shape )"
      ],
      "metadata": {
        "id": "1Q3B2kmiU7s8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aaff4d91-c4e3-48af-9534-7f0957b2543d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1000, 200) (10000, 200)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import confusion_matrix\n",
        "Y_test_model = test_labels[1].to_numpy()\n",
        "Y_train_model = train_df['misogynous'].to_numpy()\n",
        "clf = KNeighborsClassifier(n_jobs=5)\n",
        "clf.fit(X_train_pad_2_vec[:8000], Y_train_model[:8000])\n",
        "print(\"######## Misogynous Prediction ########\")\n",
        "print(\"\\nTraining Dataset \")\n",
        "y_pred = clf.predict(X_train_pad_2_vec[:8000])\n",
        "print(confusion_matrix(Y_train_model[:8000], y_pred),\"\\n F1 score - \", f1_score(Y_train_model[:8000], y_pred, average='macro'))\n",
        "print(\"\\nValidation Dataset \")\n",
        "y_pred = clf.predict(X_train_pad_2_vec[8000:])\n",
        "print(confusion_matrix(Y_train_model[8000:], y_pred),\"\\n F1 score - \", f1_score(Y_train_model[8000:], y_pred, average='macro'))\n",
        "y_pred = clf.predict(X_test_pad_2_vec)\n",
        "print(\"\\nSubmission Score \")\n",
        "print(confusion_matrix(Y_test_model, y_pred),\"\\n F1 score - \", f1_score(Y_test_model, y_pred, average='macro'))\n",
        "subtaskA = f1_score(Y_test_model, y_pred, average='macro')\n",
        "subtaskB = f1_score(Y_test_model, y_pred, average='macro')*(Y_test_model.sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eeexSaGHPhuH",
        "outputId": "d34729af-7260-4c5a-f3fe-f2aa18738b52"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "######## Misogynous Prediction ########\n",
            "\n",
            "Training Dataset \n",
            "[[2961 1002]\n",
            " [ 751 3286]] \n",
            " F1 score -  0.7805127603173205\n",
            "\n",
            "Validation Dataset \n",
            "[[618 419]\n",
            " [295 668]] \n",
            " F1 score -  0.6427767354596623\n",
            "\n",
            "Submission Score \n",
            "[[214 286]\n",
            " [128 372]] \n",
            " F1 score -  0.5754002929122617\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Y_train_model = train_df['shaming'].to_numpy()\n",
        "Y_test_model = test_labels[2].to_numpy()\n",
        "clf = KNeighborsClassifier(n_jobs=5)\n",
        "clf.fit(X_train_pad_2_vec[:8000], Y_train_model[:8000])\n",
        "print(\"######## Shaming Prediction ########\")\n",
        "print(\"\\nTraining Dataset \")\n",
        "y_pred = clf.predict(X_train_pad_2_vec[:8000])\n",
        "print(confusion_matrix(Y_train_model[:8000], y_pred),\"\\n F1 score - \", f1_score(Y_train_model[:8000], y_pred, average='macro'))\n",
        "print(\"\\nValidation Dataset \")\n",
        "y_pred = clf.predict(X_train_pad_2_vec[8000:])\n",
        "print(confusion_matrix(Y_train_model[8000:], y_pred),\"\\n F1 score - \", f1_score(Y_train_model[8000:], y_pred, average='macro'))\n",
        "y_pred = clf.predict(X_test_pad_2_vec)\n",
        "print(\"\\n######## Shaming Prediction ########\")\n",
        "print(confusion_matrix(Y_test_model, y_pred),\"\\n F1 score - \", f1_score(Y_test_model, y_pred, average='macro'))\n",
        "subtaskB += f1_score(Y_test_model, y_pred, average='macro')*(Y_test_model.sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yoONDfsDbebh",
        "outputId": "5afbfc09-3a06-4bd3-80c0-16feb8b853d5"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "######## Shaming Prediction ########\n",
            "\n",
            "Training Dataset \n",
            "[[6866   78]\n",
            " [ 854  202]] \n",
            " F1 score -  0.6194190996076587\n",
            "\n",
            "Validation Dataset \n",
            "[[1746   36]\n",
            " [ 200   18]] \n",
            " F1 score -  0.5345241100732138\n",
            "\n",
            "######## Shaming Prediction ########\n",
            "[[827  27]\n",
            " [131  15]] \n",
            " F1 score -  0.5361890000469682\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Y_train_model = train_df['stereotype'].to_numpy()\n",
        "Y_test_model = test_labels[3].to_numpy()\n",
        "clf = KNeighborsClassifier(n_jobs=5)\n",
        "clf.fit(X_train_pad_2_vec[:8000], Y_train_model[:8000])\n",
        "print(\"######## Stereotype Prediction ########\")\n",
        "print(\"\\nTraining Dataset \")\n",
        "y_pred = clf.predict(X_train_pad_2_vec[:8000])\n",
        "print(confusion_matrix(Y_train_model[:8000], y_pred),\"\\n F1 score - \", f1_score(Y_train_model[:8000], y_pred, average='macro'))\n",
        "print(\"\\nValidation Dataset \")\n",
        "y_pred = clf.predict(X_train_pad_2_vec[8000:])\n",
        "print(confusion_matrix(Y_train_model[8000:], y_pred),\"\\n F1 score - \", f1_score(Y_train_model[8000:], y_pred, average='macro'))\n",
        "y_pred = clf.predict(X_test_pad_2_vec)\n",
        "print(\"\\n######## Stereotype Prediction ########\")\n",
        "print(confusion_matrix(Y_test_model, y_pred),\"\\n F1 score - \", f1_score(Y_test_model, y_pred, average='macro'))\n",
        "subtaskB += f1_score(Y_test_model, y_pred, average='macro')*(Y_test_model.sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NjFZV3NocJYc",
        "outputId": "790dc186-8c94-49f6-8751-5cc6ea6ac0cd"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "######## Stereotype Prediction ########\n",
            "\n",
            "Training Dataset \n",
            "[[5100  484]\n",
            " [1171 1245]] \n",
            " F1 score -  0.7305601103808128\n",
            "\n",
            "Validation Dataset \n",
            "[[1351  255]\n",
            " [ 258  136]] \n",
            " F1 score -  0.5934661370367802\n",
            "\n",
            "######## Stereotype Prediction ########\n",
            "[[534 116]\n",
            " [230 120]] \n",
            " F1 score -  0.5824302079159647\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Y_train_model = train_df['objectification'].to_numpy()\n",
        "Y_test_model = test_labels[4].to_numpy()\n",
        "clf = KNeighborsClassifier(n_jobs=5)\n",
        "clf.fit(X_train_pad_2_vec[:8000], Y_train_model[:8000])\n",
        "print(\"######## Objectification Prediction ########\")\n",
        "print(\"\\nTraining Dataset \")\n",
        "y_pred = clf.predict(X_train_pad_2_vec[:8000])\n",
        "print(confusion_matrix(Y_train_model[:8000], y_pred),\"\\n F1 score - \", f1_score(Y_train_model[:8000], y_pred, average='macro'))\n",
        "print(\"\\nValidation Dataset \")\n",
        "y_pred = clf.predict(X_train_pad_2_vec[8000:])\n",
        "print(confusion_matrix(Y_train_model[8000:], y_pred),\"\\n F1 score - \", f1_score(Y_train_model[8000:], y_pred, average='macro'))\n",
        "y_pred = clf.predict(X_test_pad_2_vec)\n",
        "print(\"\\n######## Objectification Prediction ########\")\n",
        "print(confusion_matrix(Y_test_model, y_pred),\"\\n F1 score - \", f1_score(Y_test_model, y_pred, average='macro'))\n",
        "subtaskB += f1_score(Y_test_model, y_pred, average='macro')*(Y_test_model.sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "43ZAB6vodMCx",
        "outputId": "e7a99be1-d3ad-4d05-8655-3466fb3da133"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "######## Objectification Prediction ########\n",
            "\n",
            "Training Dataset \n",
            "[[5880  287]\n",
            " [1147  686]] \n",
            " F1 score -  0.6901332394657456\n",
            "\n",
            "Validation Dataset \n",
            "[[1484  147]\n",
            " [ 288   81]] \n",
            " F1 score -  0.5717641986009979\n",
            "\n",
            "######## Objectification Prediction ########\n",
            "[[570  82]\n",
            " [265  83]] \n",
            " F1 score -  0.54511549740375\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Y_train_model = train_df['violence'].to_numpy()\n",
        "Y_test_model = test_labels[5].to_numpy()\n",
        "clf = KNeighborsClassifier(n_jobs=5)\n",
        "clf.fit(X_train_pad_2_vec[:8000], Y_train_model[:8000])\n",
        "print(\"######## Violence Prediction ########\")\n",
        "print(\"\\nTraining Dataset \")\n",
        "y_pred = clf.predict(X_train_pad_2_vec[:8000])\n",
        "print(confusion_matrix(Y_train_model[:8000], y_pred),\"\\n F1 score - \", f1_score(Y_train_model[:8000], y_pred, average='macro'))\n",
        "print(\"\\nValidation Dataset \")\n",
        "y_pred = clf.predict(X_train_pad_2_vec[8000:])\n",
        "print(confusion_matrix(Y_train_model[8000:], y_pred),\"\\n F1 score - \", f1_score(Y_train_model[8000:], y_pred, average='macro'))\n",
        "y_pred = clf.predict(X_test_pad_2_vec)\n",
        "print(\"\\n######## Violence Prediction ########\")\n",
        "print(confusion_matrix(Y_test_model, y_pred),\"\\n F1 score - \", f1_score(Y_test_model, y_pred, average='macro'))\n",
        "subtaskB += f1_score(Y_test_model, y_pred, average='macro')*(Y_test_model.sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FppcF3lAf5M0",
        "outputId": "ce0d542b-f1c0-4002-d874-f7f7ae24c16f"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "######## Violence Prediction ########\n",
            "\n",
            "Training Dataset \n",
            "[[7100   69]\n",
            " [ 643  188]] \n",
            " F1 score -  0.6489207270891189\n",
            "\n",
            "Validation Dataset \n",
            "[[1829   49]\n",
            " [ 111   11]] \n",
            " F1 score -  0.5394861817072398\n",
            "\n",
            "######## Violence Prediction ########\n",
            "[[830  17]\n",
            " [133  20]] \n",
            " F1 score -  0.5638266938063391\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Subtask A score -\", \n",
        "      subtaskA, \n",
        "      \"\\n Subtask B score - \", \n",
        "      subtaskB/(test_labels[5].sum()+ test_labels[4].sum()+ test_labels[3].sum()+test_labels[2].sum()+test_labels[1].sum()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EIlzjX4OmeHg",
        "outputId": "b6f4fec1-fdc3-497b-8c73-e0a40ee71778"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Subtask A score - 0.5754002929122617 \n",
            " Subtask B score -  0.5649966536288916\n"
          ]
        }
      ]
    }
  ]
}