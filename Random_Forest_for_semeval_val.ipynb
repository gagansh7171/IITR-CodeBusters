{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Random_Forest_for_semeval_val.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi\n",
        "!wget http://nlp.stanford.edu/data/glove.6B.zip\n",
        "!unzip -q glove.6B.zip"
      ],
      "metadata": {
        "id": "90qK_fohDCot",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "147f60b5-c3c7-4310-a535-b66d602a40d0"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: nvidia-smi: command not found\n",
            "--2022-02-13 10:03:16--  http://nlp.stanford.edu/data/glove.6B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
            "--2022-02-13 10:03:16--  https://nlp.stanford.edu/data/glove.6B.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
            "--2022-02-13 10:03:16--  http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: ‘glove.6B.zip’\n",
            "\n",
            "glove.6B.zip        100%[===================>] 822.24M  5.19MB/s    in 2m 40s  \n",
            "\n",
            "2022-02-13 10:05:56 (5.14 MB/s) - ‘glove.6B.zip’ saved [862182613/862182613]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gHdtkkNH_lDW",
        "outputId": "3d9ec89d-1acd-4e09-d4b5-910eb6801001"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10000,) (10000,)\n",
            "5000\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "import re\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score\n",
        "train_df = pd.read_csv('mami_training.csv', sep='\\t', lineterminator='\\r')\n",
        "test_df = pd.read_csv('Test.csv', sep='\\t', lineterminator='\\n')\n",
        "test_labels = pd.read_csv('test_labels.txt',header=None, sep='\\t', lineterminator='\\n')\n",
        "X = train_df['Text Transcription'].copy()\n",
        "for i in range(len(X)):\n",
        "  X[i] = X[i].lower()\n",
        "X_test_model = test_df['Text Transcription'].to_numpy()\n",
        "for i in range(len(X_test_model)):\n",
        "  X_test_model[i] = X_test_model[i].lower()\n",
        "Y = train_df['misogynous']\n",
        "X_train_model = X[:].to_numpy()\n",
        "Y_train_model = Y[:].to_numpy()\n",
        "print(X_train_model.shape, Y_train_model.shape)\n",
        "print(Y_train_model.sum())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings_index = {}\n",
        "\n",
        "f = open('glove.6B.200d.txt')\n",
        "for line in f:\n",
        "    values = line.split()\n",
        "    word = value = values[0]\n",
        "    coefs = np.asarray(values[1:], dtype='float32')\n",
        "    embeddings_index[word] = coefs\n",
        "f.close()\n",
        "\n",
        "print('Found %s word vectors.' %len(embeddings_index))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J77pLTH0OHUa",
        "outputId": "8e7128c8-888b-4e85-f81c-87f5274393a7"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 400000 word vectors.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.python.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.python.keras.preprocessing.sequence  import pad_sequences\n",
        "\n",
        "tokenizer_obj = Tokenizer()\n",
        "total_memes =  train_df['Text Transcription']\n",
        "tokenizer_obj.fit_on_texts(total_memes)\n",
        "\n",
        "max_length = 50 #max([len(s.split()) for s in total_memes])\n",
        "vocab_size  = len(tokenizer_obj.word_index) + 1\n",
        "X_train_tokens = tokenizer_obj.texts_to_sequences(X_train_model)\n",
        "X_test_tokens = tokenizer_obj.texts_to_sequences(X_test_model)\n",
        "X_train_pad = pad_sequences(X_train_tokens, maxlen=max_length)\n",
        "X_test_pad = pad_sequences(X_test_tokens, maxlen=max_length)\n",
        "print(vocab_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qIdPEBUBOZ2s",
        "outputId": "6336f825-44e9-49ea-c97b-29464c1ccc0e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20693\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "EMBEDDING_DIM = 200\n",
        "word_index = tokenizer_obj.word_index\n",
        "embedding_matrix = np.zeros((vocab_size, EMBEDDING_DIM))\n",
        "for word, i in word_index.items():\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None:\n",
        "      embedding_matrix[i] = embedding_vector\n",
        "\n",
        "def average_glove(df):\n",
        "  real_X = np.zeros((len(df) , EMBEDDING_DIM))\n",
        "  for i in range(len(df)):\n",
        "    num = 0\n",
        "    for word in df[i]:\n",
        "      num += 1\n",
        "      real_X[i] += embedding_matrix[int(word)]\n",
        "    if num!=0:\n",
        "      real_X[i] = real_X[i]/num\n",
        "  return real_X\n",
        "\n",
        "X_train_pad_2_vec = average_glove(X_train_pad)\n",
        "X_test_pad_2_vec = average_glove(X_test_pad)\n",
        "print(X_test_pad_2_vec.shape,X_train_pad_2_vec.shape )"
      ],
      "metadata": {
        "id": "1Q3B2kmiU7s8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b7d71a7c-7eb2-4dd6-baea-479189de3cf1"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1000, 200) (10000, 200)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import confusion_matrix\n",
        "Y_test_model = test_labels[1].to_numpy()\n",
        "Y_train_model = train_df['misogynous'].to_numpy()\n",
        "clf = RandomForestClassifier(n_jobs=5, bootstrap=True,oob_score=True, n_estimators=10, max_features=None)\n",
        "clf.fit(X_train_pad_2_vec[:8000], Y_train_model[:8000])\n",
        "print(\"######## Misogynous Prediction ########\")\n",
        "print(\"\\nTraining Dataset \")\n",
        "y_pred = clf.predict(X_train_pad_2_vec[:8000])\n",
        "print(confusion_matrix(Y_train_model[:8000], y_pred),\"\\n F1 score - \", f1_score(Y_train_model[:8000], y_pred, average='macro'))\n",
        "print(\"\\nValidation Dataset \")\n",
        "y_pred = clf.predict(X_train_pad_2_vec[8000:])\n",
        "print(confusion_matrix(Y_train_model[8000:], y_pred),\"\\n F1 score - \", f1_score(Y_train_model[8000:], y_pred, average='macro'))\n",
        "y_pred = clf.predict(X_test_pad_2_vec)\n",
        "print(\"\\nSubmission Score \")\n",
        "print(confusion_matrix(Y_test_model, y_pred),\"\\n F1 score - \", f1_score(Y_test_model, y_pred, average='macro'))\n",
        "subtaskA = f1_score(Y_test_model, y_pred, average='macro')\n",
        "subtaskB = f1_score(Y_test_model, y_pred, average='macro')*(Y_test_model.sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eeexSaGHPhuH",
        "outputId": "a17afd9f-50fe-4586-8109-bb89badac572"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/ensemble/_forest.py:564: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "######## Misogynous Prediction ########\n",
            "\n",
            "Training Dataset \n",
            "[[3931   32]\n",
            " [  83 3954]] \n",
            " F1 score -  0.9856248811806585\n",
            "\n",
            "Validation Dataset \n",
            "[[715 322]\n",
            " [432 531]] \n",
            " F1 score -  0.6197818334382212\n",
            "\n",
            "Submission Score \n",
            "[[284 216]\n",
            " [195 305]] \n",
            " F1 score -  0.5888186690330436\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Y_train_model = train_df['shaming'].to_numpy()\n",
        "Y_test_model = test_labels[2].to_numpy()\n",
        "clf = RandomForestClassifier(n_jobs=5, bootstrap=True,oob_score=True, n_estimators=10, max_features=None)\n",
        "clf.fit(X_train_pad_2_vec[:8000], Y_train_model[:8000])\n",
        "print(\"######## Shaming Prediction ########\")\n",
        "print(\"\\nTraining Dataset \")\n",
        "y_pred = clf.predict(X_train_pad_2_vec[:8000])\n",
        "print(confusion_matrix(Y_train_model[:8000], y_pred),\"\\n F1 score - \", f1_score(Y_train_model[:8000], y_pred, average='macro'))\n",
        "print(\"\\nValidation Dataset \")\n",
        "y_pred = clf.predict(X_train_pad_2_vec[8000:])\n",
        "print(confusion_matrix(Y_train_model[8000:], y_pred),\"\\n F1 score - \", f1_score(Y_train_model[8000:], y_pred, average='macro'))\n",
        "y_pred = clf.predict(X_test_pad_2_vec)\n",
        "print(\"\\n######## Shaming Prediction ########\")\n",
        "print(confusion_matrix(Y_test_model, y_pred),\"\\n F1 score - \", f1_score(Y_test_model, y_pred, average='macro'))\n",
        "subtaskB += f1_score(Y_test_model, y_pred, average='macro')*(Y_test_model.sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yoONDfsDbebh",
        "outputId": "2a38d441-e2b4-4b3d-a692-70450b439628"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/ensemble/_forest.py:564: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "######## Shaming Prediction ########\n",
            "\n",
            "Training Dataset \n",
            "[[6937    7]\n",
            " [ 151  905]] \n",
            " F1 score -  0.9542277349797443\n",
            "\n",
            "Validation Dataset \n",
            "[[1749   33]\n",
            " [ 209    9]] \n",
            " F1 score -  0.502262443438914\n",
            "\n",
            "######## Shaming Prediction ########\n",
            "[[836  18]\n",
            " [142   4]] \n",
            " F1 score -  0.4801414015387815\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Y_train_model = train_df['stereotype'].to_numpy()\n",
        "Y_test_model = test_labels[3].to_numpy()\n",
        "clf = RandomForestClassifier(n_jobs=5, bootstrap=True,oob_score=True, n_estimators=10, max_features=None)\n",
        "clf.fit(X_train_pad_2_vec[:8000], Y_train_model[:8000])\n",
        "print(\"######## Stereotype Prediction ########\")\n",
        "print(\"\\nTraining Dataset \")\n",
        "y_pred = clf.predict(X_train_pad_2_vec[:8000])\n",
        "print(confusion_matrix(Y_train_model[:8000], y_pred),\"\\n F1 score - \", f1_score(Y_train_model[:8000], y_pred, average='macro'))\n",
        "print(\"\\nValidation Dataset \")\n",
        "y_pred = clf.predict(X_train_pad_2_vec[8000:])\n",
        "print(confusion_matrix(Y_train_model[8000:], y_pred),\"\\n F1 score - \", f1_score(Y_train_model[8000:], y_pred, average='macro'))\n",
        "y_pred = clf.predict(X_test_pad_2_vec)\n",
        "print(\"\\n######## Stereotype Prediction ########\")\n",
        "print(confusion_matrix(Y_test_model, y_pred),\"\\n F1 score - \", f1_score(Y_test_model, y_pred, average='macro'))\n",
        "subtaskB += f1_score(Y_test_model, y_pred, average='macro')*(Y_test_model.sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NjFZV3NocJYc",
        "outputId": "ab1fe0dd-72e7-489f-c6f7-e9e2610ae215"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/ensemble/_forest.py:564: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "######## Stereotype Prediction ########\n",
            "\n",
            "Training Dataset \n",
            "[[5567   17]\n",
            " [ 170 2246]] \n",
            " F1 score -  0.9717581099485098\n",
            "\n",
            "Validation Dataset \n",
            "[[1444  162]\n",
            " [ 308   86]] \n",
            " F1 score -  0.5639742540712744\n",
            "\n",
            "######## Stereotype Prediction ########\n",
            "[[604  46]\n",
            " [281  69]] \n",
            " F1 score -  0.5418724387937375\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Y_train_model = train_df['objectification'].to_numpy()\n",
        "Y_test_model = test_labels[4].to_numpy()\n",
        "clf = RandomForestClassifier(n_jobs=5, bootstrap=True,oob_score=True, n_estimators=10, max_features=None)\n",
        "clf.fit(X_train_pad_2_vec[:8000], Y_train_model[:8000])\n",
        "print(\"######## Objectification Prediction ########\")\n",
        "print(\"\\nTraining Dataset \")\n",
        "y_pred = clf.predict(X_train_pad_2_vec[:8000])\n",
        "print(confusion_matrix(Y_train_model[:8000], y_pred),\"\\n F1 score - \", f1_score(Y_train_model[:8000], y_pred, average='macro'))\n",
        "print(\"\\nValidation Dataset \")\n",
        "y_pred = clf.predict(X_train_pad_2_vec[8000:])\n",
        "print(confusion_matrix(Y_train_model[8000:], y_pred),\"\\n F1 score - \", f1_score(Y_train_model[8000:], y_pred, average='macro'))\n",
        "y_pred = clf.predict(X_test_pad_2_vec)\n",
        "print(\"\\n######## Objectification Prediction ########\")\n",
        "print(confusion_matrix(Y_test_model, y_pred),\"\\n F1 score - \", f1_score(Y_test_model, y_pred, average='macro'))\n",
        "subtaskB += f1_score(Y_test_model, y_pred, average='macro')*(Y_test_model.sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "43ZAB6vodMCx",
        "outputId": "8e057b1b-4850-4074-8c66-e58d15f45002"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/ensemble/_forest.py:564: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "######## Objectification Prediction ########\n",
            "\n",
            "Training Dataset \n",
            "[[6158    9]\n",
            " [ 167 1666]] \n",
            " F1 score -  0.9678699727004303\n",
            "\n",
            "Validation Dataset \n",
            "[[1547   84]\n",
            " [ 332   37]] \n",
            " F1 score -  0.5162509448223734\n",
            "\n",
            "######## Objectification Prediction ########\n",
            "[[620  32]\n",
            " [323  25]] \n",
            " F1 score -  0.45044312860404817\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Y_train_model = train_df['violence'].to_numpy()\n",
        "Y_test_model = test_labels[5].to_numpy()\n",
        "clf = RandomForestClassifier(n_jobs=5, bootstrap=True,oob_score=True, n_estimators=10, max_features=None)\n",
        "clf.fit(X_train_pad_2_vec[:8000], Y_train_model[:8000])\n",
        "print(\"######## Violence Prediction ########\")\n",
        "print(\"\\nTraining Dataset \")\n",
        "y_pred = clf.predict(X_train_pad_2_vec[:8000])\n",
        "print(confusion_matrix(Y_train_model[:8000], y_pred),\"\\n F1 score - \", f1_score(Y_train_model[:8000], y_pred, average='macro'))\n",
        "print(\"\\nValidation Dataset \")\n",
        "y_pred = clf.predict(X_train_pad_2_vec[8000:])\n",
        "print(confusion_matrix(Y_train_model[8000:], y_pred),\"\\n F1 score - \", f1_score(Y_train_model[8000:], y_pred, average='macro'))\n",
        "y_pred = clf.predict(X_test_pad_2_vec)\n",
        "print(\"\\n######## Violence Prediction ########\")\n",
        "print(confusion_matrix(Y_test_model, y_pred),\"\\n F1 score - \", f1_score(Y_test_model, y_pred, average='macro'))\n",
        "subtaskB += f1_score(Y_test_model, y_pred, average='macro')*(Y_test_model.sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FppcF3lAf5M0",
        "outputId": "f7f9665e-d974-4306-ba16-7d0138f32238"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/ensemble/_forest.py:564: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "######## Violence Prediction ########\n",
            "\n",
            "Training Dataset \n",
            "[[7163    6]\n",
            " [ 140  691]] \n",
            " F1 score -  0.947180907562247\n",
            "\n",
            "Validation Dataset \n",
            "[[1859   19]\n",
            " [ 120    2]] \n",
            " F1 score -  0.4959668280902401\n",
            "\n",
            "######## Violence Prediction ########\n",
            "[[846   1]\n",
            " [151   2]] \n",
            " F1 score -  0.47160576227821344\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Subtask A score -\", \n",
        "      subtaskA, \n",
        "      \"\\n Subtask B score - \", \n",
        "      subtaskB/(test_labels[5].sum()+ test_labels[4].sum()+ test_labels[3].sum()+test_labels[2].sum()+test_labels[1].sum()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EIlzjX4OmeHg",
        "outputId": "8deede6e-c2ad-453b-8142-ddbf8e3c0540"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Subtask A score - 0.5888186690330436 \n",
            " Subtask B score -  0.5230963414173463\n"
          ]
        }
      ]
    }
  ]
}