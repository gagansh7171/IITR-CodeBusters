{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MLP_for_semeval.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi\n",
        "!wget http://nlp.stanford.edu/data/glove.6B.zip\n",
        "!unzip -q glove.6B.zip"
      ],
      "metadata": {
        "id": "90qK_fohDCot",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c637994-d8f7-4473-bc99-a0bc21f2d034"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: nvidia-smi: command not found\n",
            "--2022-02-13 09:53:56--  http://nlp.stanford.edu/data/glove.6B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
            "--2022-02-13 09:53:56--  https://nlp.stanford.edu/data/glove.6B.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
            "--2022-02-13 09:53:56--  http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: ‘glove.6B.zip’\n",
            "\n",
            "glove.6B.zip        100%[===================>] 822.24M  5.07MB/s    in 2m 40s  \n",
            "\n",
            "2022-02-13 09:56:37 (5.13 MB/s) - ‘glove.6B.zip’ saved [862182613/862182613]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gHdtkkNH_lDW",
        "outputId": "b7edbd3c-8d79-4b6e-c846-98bb135a88d7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10000,) (10000,)\n",
            "5000\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "import re\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score\n",
        "train_df = pd.read_csv('mami_training.csv', sep='\\t', lineterminator='\\r')\n",
        "test_df = pd.read_csv('Test.csv', sep='\\t', lineterminator='\\n')\n",
        "test_labels = pd.read_csv('test_labels.txt',header=None, sep='\\t', lineterminator='\\n')\n",
        "X = train_df['Text Transcription'].copy()\n",
        "for i in range(len(X)):\n",
        "  X[i] = X[i].lower()\n",
        "X_test_model = test_df['Text Transcription'].to_numpy()\n",
        "for i in range(len(X_test_model)):\n",
        "  X_test_model[i] = X_test_model[i].lower()\n",
        "Y = train_df['misogynous']\n",
        "X_train_model = X[:].to_numpy()\n",
        "Y_train_model = Y[:].to_numpy()\n",
        "print(X_train_model.shape, Y_train_model.shape)\n",
        "print(Y_train_model.sum())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings_index = {}\n",
        "\n",
        "f = open('glove.6B.200d.txt')\n",
        "for line in f:\n",
        "    values = line.split()\n",
        "    word = value = values[0]\n",
        "    coefs = np.asarray(values[1:], dtype='float32')\n",
        "    embeddings_index[word] = coefs\n",
        "f.close()\n",
        "\n",
        "print('Found %s word vectors.' %len(embeddings_index))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J77pLTH0OHUa",
        "outputId": "ffae5432-1a81-41c3-85fb-82d49c536662"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 400000 word vectors.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.python.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.python.keras.preprocessing.sequence  import pad_sequences\n",
        "\n",
        "tokenizer_obj = Tokenizer()\n",
        "total_memes =  train_df['Text Transcription']\n",
        "tokenizer_obj.fit_on_texts(total_memes)\n",
        "\n",
        "max_length = 50 #max([len(s.split()) for s in total_memes])\n",
        "vocab_size  = len(tokenizer_obj.word_index) + 1\n",
        "X_train_tokens = tokenizer_obj.texts_to_sequences(X_train_model)\n",
        "X_test_tokens = tokenizer_obj.texts_to_sequences(X_test_model)\n",
        "X_train_pad = pad_sequences(X_train_tokens, maxlen=max_length)\n",
        "X_test_pad = pad_sequences(X_test_tokens, maxlen=max_length)\n",
        "print(vocab_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qIdPEBUBOZ2s",
        "outputId": "213225ae-4d35-485e-f84f-b5e4a83eea33"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20693\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "EMBEDDING_DIM = 200\n",
        "word_index = tokenizer_obj.word_index\n",
        "embedding_matrix = np.zeros((vocab_size, EMBEDDING_DIM))\n",
        "for word, i in word_index.items():\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None:\n",
        "      embedding_matrix[i] = embedding_vector\n",
        "\n",
        "def average_glove(df):\n",
        "  real_X = np.zeros((len(df) , EMBEDDING_DIM))\n",
        "  for i in range(len(df)):\n",
        "    num = 0\n",
        "    for word in df[i]:\n",
        "      num += 1\n",
        "      real_X[i] += embedding_matrix[int(word)]\n",
        "    if num!=0:\n",
        "      real_X[i] = real_X[i]/num\n",
        "  return real_X\n",
        "\n",
        "X_train_pad_2_vec = average_glove(X_train_pad)\n",
        "X_test_pad_2_vec = average_glove(X_test_pad)\n",
        "print(X_test_pad_2_vec.shape,X_train_pad_2_vec.shape )"
      ],
      "metadata": {
        "id": "1Q3B2kmiU7s8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5a490f57-9001-4ac4-c5e7-8572bf54c641"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1000, 200) (10000, 200)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import confusion_matrix\n",
        "Y_test_model = test_labels[1].to_numpy()\n",
        "Y_train_model = train_df['misogynous'].to_numpy()\n",
        "clf = MLPClassifier( max_iter=200)\n",
        "clf.fit(X_train_pad_2_vec[:8000], Y_train_model[:8000])\n",
        "print(\"######## Misogynous Prediction ########\")\n",
        "print(\"\\nTraining Dataset \")\n",
        "y_pred = clf.predict(X_train_pad_2_vec[:8000])\n",
        "print(confusion_matrix(Y_train_model[:8000], y_pred),\"\\n F1 score - \", f1_score(Y_train_model[:8000], y_pred, average='macro'))\n",
        "print(\"\\nValidation Dataset \")\n",
        "y_pred = clf.predict(X_train_pad_2_vec[8000:])\n",
        "print(confusion_matrix(Y_train_model[8000:], y_pred),\"\\n F1 score - \", f1_score(Y_train_model[8000:], y_pred, average='macro'))\n",
        "y_pred = clf.predict(X_test_pad_2_vec)\n",
        "print(\"\\nSubmission Score \")\n",
        "print(confusion_matrix(Y_test_model, y_pred),\"\\n F1 score - \", f1_score(Y_test_model, y_pred, average='macro'))\n",
        "subtaskA = f1_score(Y_test_model, y_pred, average='macro')\n",
        "subtaskB = f1_score(Y_test_model, y_pred, average='macro')*(Y_test_model.sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eeexSaGHPhuH",
        "outputId": "16c5890f-b406-427e-b02c-2511a5e5f33c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "######## Misogynous Prediction ########\n",
            "\n",
            "Training Dataset \n",
            "[[3599  364]\n",
            " [ 438 3599]] \n",
            " F1 score -  0.89975\n",
            "\n",
            "Validation Dataset \n",
            "[[745 292]\n",
            " [281 682]] \n",
            " F1 score -  0.7132154380183737\n",
            "\n",
            "Submission Score \n",
            "[[220 280]\n",
            " [130 370]] \n",
            " F1 score -  0.5805626598465473\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  ConvergenceWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Y_train_model = train_df['shaming'].to_numpy()\n",
        "Y_test_model = test_labels[2].to_numpy()\n",
        "clf = MLPClassifier( max_iter=200)\n",
        "clf.fit(X_train_pad_2_vec[:8000], Y_train_model[:8000])\n",
        "print(\"######## Shaming Prediction ########\")\n",
        "print(\"\\nTraining Dataset \")\n",
        "y_pred = clf.predict(X_train_pad_2_vec[:8000])\n",
        "print(confusion_matrix(Y_train_model[:8000], y_pred),\"\\n F1 score - \", f1_score(Y_train_model[:8000], y_pred, average='macro'))\n",
        "print(\"\\nValidation Dataset \")\n",
        "y_pred = clf.predict(X_train_pad_2_vec[8000:])\n",
        "print(confusion_matrix(Y_train_model[8000:], y_pred),\"\\n F1 score - \", f1_score(Y_train_model[8000:], y_pred, average='macro'))\n",
        "y_pred = clf.predict(X_test_pad_2_vec)\n",
        "print(\"\\n######## Shaming Prediction ########\")\n",
        "print(confusion_matrix(Y_test_model, y_pred),\"\\n F1 score - \", f1_score(Y_test_model, y_pred, average='macro'))\n",
        "subtaskB += f1_score(Y_test_model, y_pred, average='macro')*(Y_test_model.sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yoONDfsDbebh",
        "outputId": "48e687a2-2144-42f7-fbf7-15eb11a936a5"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "######## Shaming Prediction ########\n",
            "\n",
            "Training Dataset \n",
            "[[6930   14]\n",
            " [ 353  703]] \n",
            " F1 score -  0.8836050912623699\n",
            "\n",
            "Validation Dataset \n",
            "[[1709   73]\n",
            " [ 170   48]] \n",
            " F1 score -  0.6084052667074377\n",
            "\n",
            "######## Shaming Prediction ########\n",
            "[[794  60]\n",
            " [129  17]] \n",
            " F1 score -  0.5230536678182356\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  ConvergenceWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Y_train_model = train_df['stereotype'].to_numpy()\n",
        "Y_test_model = test_labels[3].to_numpy()\n",
        "clf = MLPClassifier( max_iter=200)\n",
        "clf.fit(X_train_pad_2_vec[:8000], Y_train_model[:8000])\n",
        "print(\"######## Stereotype Prediction ########\")\n",
        "print(\"\\nTraining Dataset \")\n",
        "y_pred = clf.predict(X_train_pad_2_vec[:8000])\n",
        "print(confusion_matrix(Y_train_model[:8000], y_pred),\"\\n F1 score - \", f1_score(Y_train_model[:8000], y_pred, average='macro'))\n",
        "print(\"\\nValidation Dataset \")\n",
        "y_pred = clf.predict(X_train_pad_2_vec[8000:])\n",
        "print(confusion_matrix(Y_train_model[8000:], y_pred),\"\\n F1 score - \", f1_score(Y_train_model[8000:], y_pred, average='macro'))\n",
        "y_pred = clf.predict(X_test_pad_2_vec)\n",
        "print(\"\\n######## Stereotype Prediction ########\")\n",
        "print(confusion_matrix(Y_test_model, y_pred),\"\\n F1 score - \", f1_score(Y_test_model, y_pred, average='macro'))\n",
        "subtaskB += f1_score(Y_test_model, y_pred, average='macro')*(Y_test_model.sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NjFZV3NocJYc",
        "outputId": "8d726d3b-b28f-467a-f2c8-d718baa9fee7"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "######## Stereotype Prediction ########\n",
            "\n",
            "Training Dataset \n",
            "[[5484  100]\n",
            " [ 615 1801]] \n",
            " F1 score -  0.8865878448222722\n",
            "\n",
            "Validation Dataset \n",
            "[[1411  195]\n",
            " [ 215  179]] \n",
            " F1 score -  0.6696446988448845\n",
            "\n",
            "######## Stereotype Prediction ########\n",
            "[[524 126]\n",
            " [248 102]] \n",
            " F1 score -  0.544965665591131\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  ConvergenceWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Y_train_model = train_df['objectification'].to_numpy()\n",
        "Y_test_model = test_labels[4].to_numpy()\n",
        "clf = MLPClassifier( max_iter=200)\n",
        "clf.fit(X_train_pad_2_vec[:8000], Y_train_model[:8000])\n",
        "print(\"######## Objectification Prediction ########\")\n",
        "print(\"\\nTraining Dataset \")\n",
        "y_pred = clf.predict(X_train_pad_2_vec[:8000])\n",
        "print(confusion_matrix(Y_train_model[:8000], y_pred),\"\\n F1 score - \", f1_score(Y_train_model[:8000], y_pred, average='macro'))\n",
        "print(\"\\nValidation Dataset \")\n",
        "y_pred = clf.predict(X_train_pad_2_vec[8000:])\n",
        "print(confusion_matrix(Y_train_model[8000:], y_pred),\"\\n F1 score - \", f1_score(Y_train_model[8000:], y_pred, average='macro'))\n",
        "y_pred = clf.predict(X_test_pad_2_vec)\n",
        "print(\"\\n######## Objectification Prediction ########\")\n",
        "print(confusion_matrix(Y_test_model, y_pred),\"\\n F1 score - \", f1_score(Y_test_model, y_pred, average='macro'))\n",
        "subtaskB += f1_score(Y_test_model, y_pred, average='macro')*(Y_test_model.sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "43ZAB6vodMCx",
        "outputId": "87121c3a-31e0-4090-e3ef-36d49a33f6af"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "######## Objectification Prediction ########\n",
            "\n",
            "Training Dataset \n",
            "[[6082   85]\n",
            " [ 392 1441]] \n",
            " F1 score -  0.9101295469862676\n",
            "\n",
            "Validation Dataset \n",
            "[[1440  191]\n",
            " [ 241  128]] \n",
            " F1 score -  0.6208291203235592\n",
            "\n",
            "######## Objectification Prediction ########\n",
            "[[552 100]\n",
            " [222 126]] \n",
            " F1 score -  0.6066089693154997\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  ConvergenceWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Y_train_model = train_df['violence'].to_numpy()\n",
        "Y_test_model = test_labels[5].to_numpy()\n",
        "clf = MLPClassifier( max_iter=200)\n",
        "clf.fit(X_train_pad_2_vec[:8000], Y_train_model[:8000])\n",
        "print(\"######## Violence Prediction ########\")\n",
        "print(\"\\nTraining Dataset \")\n",
        "y_pred = clf.predict(X_train_pad_2_vec[:8000])\n",
        "print(confusion_matrix(Y_train_model[:8000], y_pred),\"\\n F1 score - \", f1_score(Y_train_model[:8000], y_pred, average='macro'))\n",
        "print(\"\\nValidation Dataset \")\n",
        "y_pred = clf.predict(X_train_pad_2_vec[8000:])\n",
        "print(confusion_matrix(Y_train_model[8000:], y_pred),\"\\n F1 score - \", f1_score(Y_train_model[8000:], y_pred, average='macro'))\n",
        "y_pred = clf.predict(X_test_pad_2_vec)\n",
        "print(\"\\n######## Violence Prediction ########\")\n",
        "print(confusion_matrix(Y_test_model, y_pred),\"\\n F1 score - \", f1_score(Y_test_model, y_pred, average='macro'))\n",
        "subtaskB += f1_score(Y_test_model, y_pred, average='macro')*(Y_test_model.sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FppcF3lAf5M0",
        "outputId": "f164160d-8d78-4295-cc75-71606d40b847"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "######## Violence Prediction ########\n",
            "\n",
            "Training Dataset \n",
            "[[7147   22]\n",
            " [ 291  540]] \n",
            " F1 score -  0.8769385072434515\n",
            "\n",
            "Validation Dataset \n",
            "[[1808   70]\n",
            " [  88   34]] \n",
            " F1 score -  0.6295097804728205\n",
            "\n",
            "######## Violence Prediction ########\n",
            "[[828  19]\n",
            " [119  34]] \n",
            " F1 score -  0.6265870052277819\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  ConvergenceWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Subtask A score -\", \n",
        "      subtaskA, \n",
        "      \"\\n Subtask B score - \", \n",
        "      subtaskB/(test_labels[5].sum()+ test_labels[4].sum()+ test_labels[3].sum()+test_labels[2].sum()+test_labels[1].sum()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EIlzjX4OmeHg",
        "outputId": "757f3b0f-2a25-449b-fcac-91febcb9a8e1"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Subtask A score - 0.5805626598465473 \n",
            " Subtask B score -  0.5773900344043262\n"
          ]
        }
      ]
    }
  ]
}